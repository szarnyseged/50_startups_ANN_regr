{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c502b69-8557-45bb-a677-eb81596ed470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ANN for 50_Startups (regression model)\n",
    "# dataset: where do startup companies spend money on, determines the profit they earn.\n",
    "# build a model to predict the profit of a new startup company, depending on its investments (and other features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239f22a8-083f-4e9e-9187-b6c1fa5a6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea890d-8c49-4ff1-bfba-66af214f360e",
   "metadata": {},
   "source": [
    "# 1. preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad91026-cc1d-4603-8e34-1168bf9bdf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./50_Startups.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4bc93fd-f6aa-45ea-8106-a483e656d335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4)\n",
      "[[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " [144372.41 118671.85 383199.62 'New York']\n",
      " [142107.34 91391.77 366168.42 'Florida']\n",
      " [131876.9 99814.71 362861.36 'New York']\n",
      " [134615.46 147198.87 127716.82 'California']\n",
      " [130298.13 145530.06 323876.68 'Florida']\n",
      " [120542.52 148718.95 311613.29 'New York']\n",
      " [123334.88 108679.17 304981.62 'California']]\n",
      "\n",
      "y_dependent:  [[192261.83]\n",
      " [191792.06]\n",
      " [191050.39]\n",
      " [182901.99]\n",
      " [166187.94]\n",
      " [156991.12]\n",
      " [156122.51]\n",
      " [155752.6 ]\n",
      " [152211.77]\n",
      " [149759.96]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# no missing data\n",
    "X_independent = df.iloc[:, :-1].values\n",
    "y_dependent = df.iloc[:, -1].values\n",
    "y_dependent = y_dependent.reshape(-1, 1)\n",
    "print(X_independent.shape)\n",
    "print(X_independent[:10, :])\n",
    "print(\"\")\n",
    "print(\"y_dependent: \", y_dependent[:10, :])\n",
    "print(type(X_independent))\n",
    "print(type(X_independent[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745b6737-8494-4f83-946e-7237b940966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [1.0 0.0 0.0 123334.88 108679.17 304981.62]]\n"
     ]
    }
   ],
   "source": [
    "ct = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [3])], remainder=\"passthrough\")\n",
    "X_independent = np.array(ct.fit_transform(X_independent))\n",
    "print(X_independent[:10, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f070835a-56db-4246-b77f-aaf9d00c2edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (35, 6)\n",
      "X_train:  [[0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [1.0 0.0 0.0 0.0 116983.8 45173.06]\n",
      " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
      " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
      " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [0.0 0.0 1.0 61136.38 152701.92 88218.23]]\n",
      "\n",
      "y_test shape:  (15, 1)\n",
      "y_test:  [[ 89949.14]\n",
      " [132602.65]\n",
      " [111313.02]\n",
      " [ 97427.84]\n",
      " [110352.25]\n",
      " [191792.06]\n",
      " [105733.54]\n",
      " [ 49490.75]\n",
      " [ 71498.49]\n",
      " [ 42559.73]\n",
      " [126992.93]\n",
      " [108552.04]\n",
      " [155752.6 ]\n",
      " [ 64926.08]\n",
      " [124266.9 ]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_independent, y_dependent, test_size=0.3, random_state=101)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_train: \", X_train)\n",
    "print(\"\")\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "print(\"y_test: \", y_test)\n",
    "print(type(X_train))\n",
    "print(type(X_train[1]))\n",
    "\n",
    "# because of df.iloc[].values -> .values returns with bad dtypes. must convert them.\n",
    "# this is only necessary if you skip the scaling entirely. (scaling functions solve this issue)\n",
    "# otherwise -> torch tensor error: TypeError: can't convert np.ndarray of type numpy.object_.\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "print(type(X_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1f8c49-40d7-4291-976e-055939ec0b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train scaled:  [[-6.7700320e-01 -6.3245559e-01  1.2247449e+00  1.5258845e+00\n",
      "  -5.3207688e-02  1.4378211e+00]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01 -1.0793741e+00\n",
      "  -1.2595519e+00 -3.9302912e-01]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01 -3.1663558e-01\n",
      "  -1.6085771e-01 -1.0069102e+00]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00  8.5826629e-01\n",
      "   8.6923853e-02  4.2145783e-01]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01  2.2992694e-03\n",
      "  -2.2387207e-01  7.3022741e-01]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00 -1.3564342e+00\n",
      "   2.5619930e-01 -1.4722804e+00]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00 -1.2507771e+00\n",
      "  -1.9260339e+00 -2.1897160e-01]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01 -1.2072036e+00\n",
      "   1.2303319e+00 -1.5325427e+00]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01 -8.4082019e-01\n",
      "  -1.3209569e+00 -3.0490050e-01]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01  5.7621062e-01\n",
      "  -3.4014019e-01  1.4845464e-01]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01 -1.7032459e+00\n",
      "  -1.1316971e-01 -1.3915989e+00]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01 -2.5691143e-01\n",
      "   6.8852496e-01 -6.1491251e-01]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01 -4.6203086e-01\n",
      "  -6.0785115e-01  2.6864925e-02]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01 -1.0621330e+00\n",
      "   2.4461627e-01 -8.6202547e-02]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01  1.7287302e+00\n",
      "  -6.7576611e-01  1.6448624e+00]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00 -9.0438724e-02\n",
      "   2.7332947e-01  1.1865766e+00]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01 -6.6484910e-01\n",
      "   1.3329098e+00 -5.2535068e-03]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00 -6.7406535e-01\n",
      "  -1.2475930e+00 -4.9449518e-02]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00  9.9288934e-01\n",
      "   1.0141066e+00  8.3861428e-01]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00  2.2967537e-01\n",
      "   1.1844372e+00 -1.7697159e+00]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00 -2.3586962e-01\n",
      "   1.1673142e+00 -8.7292397e-01]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01  3.9617392e-01\n",
      "   2.5400001e-01  3.2154197e-01]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00  1.2464018e+00\n",
      "  -7.2303921e-01  1.2675817e+00]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00  1.9950656e+00\n",
      "   5.9420294e-01  2.1793091e+00]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01 -2.2589304e-01\n",
      "   2.2192264e+00 -7.8076726e-01]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01  1.4752226e+00\n",
      "  -1.0222335e+00  1.2952629e+00]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01 -1.0601071e+00\n",
      "  -5.7676442e-02 -3.2334575e-01]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01  3.5431784e-01\n",
      "   5.4437590e-01  3.4519255e-01]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01  1.0553452e+00\n",
      "  -4.0816140e-01  7.8310460e-01]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00 -1.6911219e+00\n",
      "  -2.4306071e+00 -1.7697159e+00]\n",
      " [-6.7700320e-01  1.5811388e+00 -8.1649661e-01 -1.9276783e-01\n",
      "  -5.1217300e-01  7.8132248e-01]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01  1.3076540e+00\n",
      "   9.6011138e-01 -7.0067406e-01]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00  4.1391978e-01\n",
      "   8.8475996e-01  5.9554625e-01]\n",
      " [ 1.4770980e+00 -6.3245559e-01 -8.1649661e-01  5.4845095e-01\n",
      "  -1.0080663e+00  3.2074770e-01]\n",
      " [-6.7700320e-01 -6.3245559e-01  1.2247449e+00 -3.3582845e-01\n",
      "   1.1555872e+00 -1.0312934e+00]]\n",
      "\n",
      "y_test scaled:  [[0.42385158]\n",
      " [0.6640442 ]\n",
      " [0.54415697]\n",
      " [0.46596602]\n",
      " [0.5387466 ]\n",
      " [0.9973547 ]\n",
      " [0.51273745]\n",
      " [0.19602022]\n",
      " [0.31995133]\n",
      " [0.15698987]\n",
      " [0.63245445]\n",
      " [0.52860916]\n",
      " [0.79440737]\n",
      " [0.28294042]\n",
      " [0.61710346]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# experiment:\n",
    "#     - scale X and y with the same scaler.\n",
    "#     - do not scaler cathegorical data, but scale the numerical.\n",
    "\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X_train = std_scaler.fit_transform(X_train)\n",
    "X_test = std_scaler.transform(X_test)\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "y_train = minmax_scaler.fit_transform(y_train)\n",
    "y_test = minmax_scaler.transform(y_test)\n",
    "\n",
    "print(\"X_train scaled: \", X_train)\n",
    "print(\"\")\n",
    "print(\"y_test scaled: \", y_test)\n",
    "print(type(X_train))\n",
    "print(type(X_train[0]))\n",
    "print(type(X_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab3105f-5bae-4c00-bc4c-42ddd7d4e9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.7700e-01, -6.3246e-01,  1.2247e+00,  1.5259e+00, -5.3208e-02,\n",
      "          1.4378e+00],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01, -1.0794e+00, -1.2596e+00,\n",
      "         -3.9303e-01],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01, -3.1664e-01, -1.6086e-01,\n",
      "         -1.0069e+00],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00,  8.5827e-01,  8.6924e-02,\n",
      "          4.2146e-01],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01,  2.2993e-03, -2.2387e-01,\n",
      "          7.3023e-01],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00, -1.3564e+00,  2.5620e-01,\n",
      "         -1.4723e+00],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00, -1.2508e+00, -1.9260e+00,\n",
      "         -2.1897e-01],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01, -1.2072e+00,  1.2303e+00,\n",
      "         -1.5325e+00],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01, -8.4082e-01, -1.3210e+00,\n",
      "         -3.0490e-01],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01,  5.7621e-01, -3.4014e-01,\n",
      "          1.4845e-01],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01, -1.7032e+00, -1.1317e-01,\n",
      "         -1.3916e+00],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01, -2.5691e-01,  6.8852e-01,\n",
      "         -6.1491e-01],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01, -4.6203e-01, -6.0785e-01,\n",
      "          2.6865e-02],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01, -1.0621e+00,  2.4462e-01,\n",
      "         -8.6203e-02],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01,  1.7287e+00, -6.7577e-01,\n",
      "          1.6449e+00],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00, -9.0439e-02,  2.7333e-01,\n",
      "          1.1866e+00],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01, -6.6485e-01,  1.3329e+00,\n",
      "         -5.2535e-03],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00, -6.7407e-01, -1.2476e+00,\n",
      "         -4.9450e-02],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00,  9.9289e-01,  1.0141e+00,\n",
      "          8.3861e-01],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00,  2.2968e-01,  1.1844e+00,\n",
      "         -1.7697e+00],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00, -2.3587e-01,  1.1673e+00,\n",
      "         -8.7292e-01],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01,  3.9617e-01,  2.5400e-01,\n",
      "          3.2154e-01],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00,  1.2464e+00, -7.2304e-01,\n",
      "          1.2676e+00],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00,  1.9951e+00,  5.9420e-01,\n",
      "          2.1793e+00],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01, -2.2589e-01,  2.2192e+00,\n",
      "         -7.8077e-01],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01,  1.4752e+00, -1.0222e+00,\n",
      "          1.2953e+00],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01, -1.0601e+00, -5.7676e-02,\n",
      "         -3.2335e-01],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01,  3.5432e-01,  5.4438e-01,\n",
      "          3.4519e-01],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01,  1.0553e+00, -4.0816e-01,\n",
      "          7.8310e-01],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00, -1.6911e+00, -2.4306e+00,\n",
      "         -1.7697e+00],\n",
      "        [-6.7700e-01,  1.5811e+00, -8.1650e-01, -1.9277e-01, -5.1217e-01,\n",
      "          7.8132e-01],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01,  1.3077e+00,  9.6011e-01,\n",
      "         -7.0067e-01],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00,  4.1392e-01,  8.8476e-01,\n",
      "          5.9555e-01],\n",
      "        [ 1.4771e+00, -6.3246e-01, -8.1650e-01,  5.4845e-01, -1.0081e+00,\n",
      "          3.2075e-01],\n",
      "        [-6.7700e-01, -6.3246e-01,  1.2247e+00, -3.3583e-01,  1.1556e+00,\n",
      "         -1.0313e+00]])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db5d72-5c01-4626-9279-b136891f7b57",
   "metadata": {},
   "source": [
    "# 2. building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a657efd8-7f06-4597-a0b8-e1579d449080",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8340f1ea-1893-4499-9ca7-57ef31f8f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init hyperparameters\n",
    "\n",
    "n_neurons = 16\n",
    "n_epochs = 600\n",
    "input_size = len(X_train[0])\n",
    "learning_batch_size = len(X_train) # BGD -> batch gradient descent, because of small dataset\n",
    "alpha_learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0bde05-17d0-431b-9208-8c74a037d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, input_size, seed=101):\n",
    "        super().__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcl1 = nn.Linear(input_size, n_neurons)\n",
    "        self.fcl2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fcl3 = nn.Linear(n_neurons, 1)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        signal = self.fcl1(data)\n",
    "        signal = F.relu(signal)\n",
    "        signal = self.fcl2(signal)\n",
    "        signal = F.relu(signal)\n",
    "        return self.fcl3(signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d133628-30da-4d46-873a-675cd8091d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "brain = Network(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77cd88b8-0c9b-4c0f-a4a0-7fea8641ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(brain.parameters(), lr=alpha_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc522a1d-90df-40d1-9714-d6716a089a91",
   "metadata": {},
   "source": [
    "# 3. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e31ff54b-a786-4cd2-8f54-3f0590933f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 10 \t Loss: 0.2049\n",
      " Epoch: 20 \t Loss: 0.1642\n",
      " Epoch: 30 \t Loss: 0.1324\n",
      " Epoch: 40 \t Loss: 0.1032\n",
      " Epoch: 50 \t Loss: 0.0749\n",
      " Epoch: 60 \t Loss: 0.0509\n",
      " Epoch: 70 \t Loss: 0.0332\n",
      " Epoch: 80 \t Loss: 0.0214\n",
      " Epoch: 90 \t Loss: 0.0139\n",
      " Epoch: 100 \t Loss: 0.0093\n",
      " Epoch: 110 \t Loss: 0.0064\n",
      " Epoch: 120 \t Loss: 0.0045\n",
      " Epoch: 130 \t Loss: 0.0033\n",
      " Epoch: 140 \t Loss: 0.0026\n",
      " Epoch: 150 \t Loss: 0.0022\n",
      " Epoch: 160 \t Loss: 0.0020\n",
      " Epoch: 170 \t Loss: 0.0018\n",
      " Epoch: 180 \t Loss: 0.0017\n",
      " Epoch: 190 \t Loss: 0.0016\n",
      " Epoch: 200 \t Loss: 0.0015\n",
      " Epoch: 210 \t Loss: 0.0014\n",
      " Epoch: 220 \t Loss: 0.0013\n",
      " Epoch: 230 \t Loss: 0.0012\n",
      " Epoch: 240 \t Loss: 0.0012\n",
      " Epoch: 250 \t Loss: 0.0011\n",
      " Epoch: 260 \t Loss: 0.0010\n",
      " Epoch: 270 \t Loss: 0.0010\n",
      " Epoch: 280 \t Loss: 0.0009\n",
      " Epoch: 290 \t Loss: 0.0009\n",
      " Epoch: 300 \t Loss: 0.0008\n",
      " Epoch: 310 \t Loss: 0.0008\n",
      " Epoch: 320 \t Loss: 0.0008\n",
      " Epoch: 330 \t Loss: 0.0007\n",
      " Epoch: 340 \t Loss: 0.0007\n",
      " Epoch: 350 \t Loss: 0.0007\n",
      " Epoch: 360 \t Loss: 0.0007\n",
      " Epoch: 370 \t Loss: 0.0007\n",
      " Epoch: 380 \t Loss: 0.0006\n",
      " Epoch: 390 \t Loss: 0.0006\n",
      " Epoch: 400 \t Loss: 0.0006\n",
      " Epoch: 410 \t Loss: 0.0006\n",
      " Epoch: 420 \t Loss: 0.0006\n",
      " Epoch: 430 \t Loss: 0.0006\n",
      " Epoch: 440 \t Loss: 0.0005\n",
      " Epoch: 450 \t Loss: 0.0005\n",
      " Epoch: 460 \t Loss: 0.0005\n",
      " Epoch: 470 \t Loss: 0.0005\n",
      " Epoch: 480 \t Loss: 0.0005\n",
      " Epoch: 490 \t Loss: 0.0005\n",
      " Epoch: 500 \t Loss: 0.0005\n",
      " Epoch: 510 \t Loss: 0.0005\n",
      " Epoch: 520 \t Loss: 0.0004\n",
      " Epoch: 530 \t Loss: 0.0004\n",
      " Epoch: 540 \t Loss: 0.0004\n",
      " Epoch: 550 \t Loss: 0.0004\n",
      " Epoch: 560 \t Loss: 0.0004\n",
      " Epoch: 570 \t Loss: 0.0004\n",
      " Epoch: 580 \t Loss: 0.0004\n",
      " Epoch: 590 \t Loss: 0.0004\n",
      " Epoch: 600 \t Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    predictions = brain(X_train)\n",
    "    loss = F.mse_loss(predictions, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # visualize\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"\\r Epoch: {} \\t Loss: {:.4f}\".format(epoch, loss.data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5834f6-4f14-4500-b642-77b8d7d43a8c",
   "metadata": {},
   "source": [
    "# check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4518bc53-fff7-4f4e-bff9-f347efeaf4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37da2a78-f48c-4727-a47b-08ac8cf734ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated: \n",
      "       y_true    y_pred\n",
      "0   0.423852  0.440186\n",
      "1   0.664044  0.796265\n",
      "2   0.544157  0.591399\n",
      "3   0.465966  0.473294\n",
      "4   0.538747  0.590854\n",
      "5   0.997355  1.013072\n",
      "6   0.512737  0.535591\n",
      "7   0.196020  0.420845\n",
      "8   0.319951  0.251292\n",
      "9   0.156990  0.047351\n",
      "10  0.632454  0.590646\n",
      "11  0.528609  0.513314\n",
      "12  0.794407  0.823783\n",
      "13  0.282940  0.212694\n",
      "14  0.617103  0.686122\n",
      "score_r2:  0.8504735408826221\n",
      "score_mse:  tensor(0.0069)\n"
     ]
    }
   ],
   "source": [
    "brain.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = brain(X_test)\n",
    "\n",
    "concatenated = np.concatenate((y_test, y_pred), axis=1)\n",
    "score_r2 = r2_score(y_test, y_pred)\n",
    "score_mse = F.mse_loss(y_pred, y_test)\n",
    "\n",
    "\n",
    "models.append({\n",
    "    \"score_r2\" : score_r2,\n",
    "    \"score_mse\" : score_mse,\n",
    "    \"n_neurons\" : n_neurons,\n",
    "    \"n_epochs\" : n_epochs,\n",
    "    \"alpha\" : alpha_learning_rate,\n",
    "    \"scaler\" : \"no scaling\"\n",
    "})\n",
    "\n",
    "print(\"concatenated: \\n\", pd.DataFrame(concatenated, columns=[\"y_true\", \"y_pred\"]))\n",
    "print(\"score_r2: \", score_r2)\n",
    "print(\"score_mse: \", score_mse.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fbfcd888-3f5f-48e7-ad2d-96d3ee5fb153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Accuracy: 80.0 %\n"
     ]
    }
   ],
   "source": [
    "# custom accuracy by chatgpt\n",
    "# threshold is the accepted difference (%) between y_true and y_pred\n",
    "\n",
    "threshold = 0.1  # You can adjust this threshold based on your problem\n",
    "\n",
    "correct_predictions = torch.abs(y_pred - y_test) <= threshold\n",
    "accuracy = torch.sum(correct_predictions).item() / len(y_test)\n",
    "\n",
    "print(\"Custom Accuracy:\", accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3df050a8-ead9-41a7-a5b3-96dbcc047ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score_r2': 0.7812195667807333, 'score_mse': tensor(0.0101), 'n_neurons': 8, 'n_epochs': 400, 'alpha': 0.001, 'scaler': 'features=std, targets=minmax'}\n",
      "{'score_r2': 0.7812195667807333, 'score_mse': tensor(0.0101), 'n_neurons': 8, 'n_epochs': 400, 'alpha': 0.001, 'scaler': 'features=std, targets=minmax'}\n",
      "{'score_r2': 0.8478386686655506, 'score_mse': tensor(0.0070), 'n_neurons': 8, 'n_epochs': 600, 'alpha': 0.001, 'scaler': 'features=std, targets=minmax'}\n",
      "{'score_r2': 0.8475171497038081, 'score_mse': tensor(0.0070), 'n_neurons': 8, 'n_epochs': 800, 'alpha': 0.001, 'scaler': 'features=std, targets=minmax'}\n",
      "{'score_r2': 0.7950949183930469, 'score_mse': tensor(0.0094), 'n_neurons': 8, 'n_epochs': 600, 'alpha': 0.003, 'scaler': 'features=std, targets=minmax'}\n",
      "{'score_r2': 0.7976605602500896, 'score_mse': tensor(0.0093), 'n_neurons': 8, 'n_epochs': 800, 'alpha': 0.003, 'scaler': 'features=std, targets=minmax'}\n",
      "{'score_r2': 0.8504687281818312, 'score_mse': tensor(0.0069), 'n_neurons': 16, 'n_epochs': 600, 'alpha': 0.001, 'scaler': 'features=std, targets=minmax'}\n"
     ]
    }
   ],
   "source": [
    "for elem in models:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2b619-d49c-4c39-b815-7516e0628226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model parameters\n",
    "save_name = \"50_Startups_checkpoint.pth\"\n",
    "torch.save(brain.state_dict(), save_name)\n",
    "print(\"saved as: \", save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
